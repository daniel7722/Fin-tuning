{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Add, GlobalAveragePooling2D,\\\n",
        "\tDense, Flatten, Conv2D, Lambda,\tInput, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import schedules, SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up Configuration "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Configuration\n",
        "def model_configuration(): \n",
        "    \"\"\"\n",
        "    Get the model configuration\n",
        "    \"\"\"\n",
        "\n",
        "    # Load dataset for computing dataset size\n",
        "    (input_train, _), (_, _) = load_dataset()\n",
        "\n",
        "    # Generic config\n",
        "    width, height, channels = 32, 32, 3\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    validation_split = 0.1\n",
        "    verbose = 1\n",
        "    n = 3\n",
        "    init_fm_dim = 16\n",
        "    shortcut_type = \"identity\"\n",
        "    \n",
        "    # Dataset size\n",
        "    train_size = (1 - validation_split)  * len(input_train)\n",
        "    val_size = (validation_split) * len(input_train)\n",
        "\n",
        "    # Number of steps per epoch is dependent on batch size\n",
        "    maximum_number_iterations = 64000\n",
        "    steps_per_epoch = tensorflow.math.floor(train_size / batch_size)\n",
        "    val_steps_per_epoch = tensorflow.math.floor(val_size / batch_size)\n",
        "    epochs = tensorflow.cast(tensorflow.math.floor(maximum_number_iterations / steps_per_epoch), dtype=tensorflow.int64)\n",
        "\n",
        "    # Define loss function\n",
        "    loss = tensorflow.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    # Learning rate config\n",
        "    boundaries = [32000, 48000]\n",
        "    values = [0.1, 0.01, 0.001]\n",
        "    lr_schedule = schedules.PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        "    # Set layer init\n",
        "    initialiser = tensorflow.keras.initializers.HeNormal()\n",
        "\n",
        "    # Define optimiser\n",
        "    optimiser_momentum = 0.9\n",
        "    optimiser_additional_metrics = [\"accuracy\"]\n",
        "    optimiser = SGD(learning_rate=lr_schedule, momentum=optimiser_momentum)\n",
        "\n",
        "    # Load Tensorboard callback\n",
        "    tensorboard = TensorBoard(\n",
        "\t    log_dir=os.path.join(os.getcwd(), \"logs\"),\n",
        "\t    histogram_freq=1,\n",
        "\t    write_images=True\n",
        "\t)\n",
        "\n",
        "    # Save a model checkpoint after every epoch\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        os.path.join(os.getcwd(), \"model_checkpoint\"),\n",
        "        save_freq=\"epoch\"\n",
        "    )\n",
        "\n",
        "    # Add callbacks to list\n",
        "    callbacks = [\n",
        "        tensorboard,\n",
        "        checkpoint\n",
        "    ]\n",
        "\n",
        "    #Create config dictionary\n",
        "    config = {\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"dim\": channels,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"validation_split\": validation_split,\n",
        "        \"verbose\": verbose,\n",
        "        \"stack_n\": n,\n",
        "        \"initial_num_feature_maps\": init_fm_dim,\n",
        "        \"training_ds_size\": train_size,\n",
        "        \"steps_per_epoch\": steps_per_epoch,\n",
        "        \"val_steps_per_epoch\": val_steps_per_epoch,\n",
        "        \"num_epochs\": epochs,\n",
        "        \"loss\": loss,\n",
        "        \"optim\": optimiser,\n",
        "        \"optim_learning_rate_schedule\": lr_schedule,\n",
        "        \"optim_momentum\": optimiser_momentum,\n",
        "        \"optim_additional_metrics\": optimiser_additional_metrics,\n",
        "        \"initialiser\": initialiser,\n",
        "        \"callbacks\": callbacks,\n",
        "        \"shortcut_type\": shortcut_type,\n",
        "        \"name\": \"ResNet20\"\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "\t\"\"\"\n",
        "\t\tLoad the CIFAR-10 dataset\n",
        "\t\"\"\"\n",
        "\treturn cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing\n",
        "## Cropping image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_crop(img, random_crop_size): \n",
        "    # Note: image_data_format is 'channel_last'\n",
        "    # SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "def crop_generator(batches, crop_length):\n",
        "    \"\"\"\n",
        "    Take as input a Keras ImageGen (Iterator) and generate random crops from the image batches generated by the original iterator\n",
        "    SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    \"\"\"\n",
        "\n",
        "    while True: \n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
        "        yield (batch_crops, batch_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocessed_dataset(): \n",
        "    \"\"\"\n",
        "    Load and preprocess the CIFAR-10 dataset\n",
        "    \"\"\"\n",
        "    (input_train, target_train), (input_test, target_test) = load_dataset()\n",
        "\n",
        "    # Retrieve shape from model configuration and unpack into components\n",
        "    config = model_configuration()\n",
        "    width, height, dim = config.get(\"width\"), config.get(\"height\"), config.get(\"dim\")\n",
        "    num_classes = config.get(\"num_classes\")\n",
        "\n",
        "    # Data augmentation: perform zero padding on datasets\n",
        "    paddings = tensorflow.constant([[0,0,], [4,4], [4,4], [0,0]])\n",
        "    input_train = tensorflow.pad(input_train, paddings, mode=\"CONSTANT\")\n",
        "\n",
        "    # Convert scalar targets to categorical ones\n",
        "    target_train = tensorflow.keras.utils.to_categorical(target_train, num_classes)\n",
        "    target_test = tensorflow.keras.utils.to_categorical(target_test, num_classes)\n",
        "\n",
        "    # Data generator for training data\n",
        "    train_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "        validation_split=config.get(\"validation_split\"),\n",
        "        horizontal_flip=True,\n",
        "        rescale=1./255,\n",
        "        preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input\n",
        "    )\n",
        "\n",
        "    # Generate training and validation batches\n",
        "    train_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"training\")\n",
        "    validation_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"validation\")\n",
        "    train_batches = crop_generator(train_batches, config.get(\"height\"))\n",
        "    validation_batches = crop_generator(validation_batches, config.get(\"height\"))\n",
        "\n",
        "    # Data generator for testing data\n",
        "    test_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input\n",
        "    )\n",
        "\n",
        "    # Generate testing batches\n",
        "    test_batches = test_generator.flow(input_test, target_test, batch_size=config.get(\"batch_size\"))\n",
        "\n",
        "    return train_batches, validation_batches, test_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating the Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def residual_block(x, number_of_filters, match_filter_size=False):\n",
        "    \"\"\"\n",
        "    Residual block for ResNet\n",
        "    \"\"\"\n",
        "    # Retrieve initialiser\n",
        "    config = model_configuration()\n",
        "    initialiser = config.get(\"initialiser\")\n",
        "\n",
        "    # Create skip connection\n",
        "    x_skip = x\n",
        "\n",
        "    # Perform the original mapping\n",
        "    if match_filter_size: \n",
        "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2, 2), kernel_initializer=initialiser,padding=\"same\")(x_skip)\n",
        "    else: \n",
        "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initialiser, padding=\"same\")(x_skip)\n",
        "\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(number_of_filters, kernel_size=(3, 3), kernel_initializer=initialiser, padding=\"same\")(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    # Perform matching of filter numbers if necessary\n",
        "    if match_filter_size and config.get(\"shortcut_type\") == \"identity\": \n",
        "        x_skip = Lambda(lambda x: tensorflow.pad(x[:, ::2, ::2, :], tensorflow.constant([[0, 0,], [0, 0], [0, 0], [number_of_filters//4, number_of_filters//4]]), mode=\"CONSTANT\"))(x_skip)\n",
        "        x_skip = BatchNormalization(axis=3)(x_skip)\n",
        "    elif match_filter_size and config.get(\"shortcut_type\") == \"projection\":\n",
        "        x_skip = Conv2D(number_of_filters, kernel_size=(1,1), kernel_initializer=initializer, strides=(2,2))(x_skip)\n",
        "    \n",
        "    # Add the skip connection to the regular mapping\n",
        "    x = Add()([x, x_skip])\n",
        "\n",
        "    # Nonlinearly activate the result\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Return the result\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ResidualBlocks(x):\n",
        "    \"\"\" \n",
        "    Set up the residual blocks\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve values\n",
        "    config = model_configuration()\n",
        "\n",
        "    # Set initial filter size\n",
        "    filter_size = config.get(\"initial_num_feature_maps\")\n",
        "\n",
        "    # 6n/2n = 3, there are 3 groups of residual blocks\n",
        "    for layer_group in range(3): \n",
        "\n",
        "        # Each block in our code has 2 weighted layers, and each group has 2n such blocks, so we have n blocks per group\n",
        "        for block in range(config.get(\"stack_n\")):\n",
        "\n",
        "            # Perform filter size increase at every first layer in the 2nd block onwards. \n",
        "            if layer_group > 0 and block == 0: \n",
        "                filter_size *= 2\n",
        "                x = residual_block(x, filter_size, match_filter_size=True)\n",
        "            else:\n",
        "                x = residual_block(x, filter_size)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_base(shp): \n",
        "    \"\"\"\n",
        "    Base Structure of the model, with residual blocks attached\n",
        "    \"\"\"\n",
        "\n",
        "    # Get number of classes from model configuration\n",
        "    config = model_configuration()\n",
        "    initialiser = config.get(\"initialiser\")\n",
        "\n",
        "    # Define model structure\n",
        "    # logits are returned becase Softmax is pushed to loss function\n",
        "    inputs = Input(shape=shp)\n",
        "    x = Conv2D(config.get(\"initial_num_feature_maps\"), kernel_size=(3, 3), strides=(1,1), kernel_initializer=initialiser, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = ResidualBlocks(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(config.get(\"num_classes\"), kernel_initializer=initialiser)(x)\n",
        "\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_model(): \n",
        "    \"\"\"\n",
        "    Initilise a compiled ResNet model\n",
        "    \"\"\"\n",
        "\n",
        "    # Get shape from model configuration\n",
        "    config = model_configuration()\n",
        "\n",
        "    # Get model base\n",
        "    inputs, outputs = model_base((config.get(\"width\"), config.get(\"height\"), config.get(\"dim\")))\n",
        "\n",
        "    # Initialise and compile model\n",
        "    model = Model(inputs, outputs, name=config.get(\"name\"))\n",
        "    model.compile(loss=config.get(\"loss\"), optimizer=config.get(\"optim\"), metrics=config.get(\"optim_additional_metrics\"))\n",
        "\n",
        "    # Print model summary\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_batches, validation_batches): \n",
        "    \"\"\"\n",
        "    Train an initialised model\n",
        "    \"\"\"\n",
        "\n",
        "    # Get model configuration\n",
        "    config = model_configuration()\n",
        "\n",
        "    # Fit data to model\n",
        "    model.fit(\n",
        "        train_batches,\n",
        "        batch_size=config.get(\"batch_size\"),\n",
        "        epochs=config.get(\"num_epochs\"),\n",
        "        verbose=config.get(\"verbose\"),\n",
        "        callbacks=config.get(\"callbacks\"),\n",
        "        steps_per_epoch=config.get(\"steps_per_epoch\"),\n",
        "        validation_data=validation_batches,\n",
        "        validation_steps=config.get(\"val_steps_per_epoch\")\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_batches): \n",
        "    \"\"\"\n",
        "    Evaluate a trained model\n",
        "    \"\"\"\n",
        "\n",
        "    # Evaluate the model\n",
        "    score = model.evaluate(test_batches, verbose=0)\n",
        "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Overall Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_process(): \n",
        "    \"\"\"\n",
        "    Run the training process for the ResNet model\n",
        "    \"\"\"\n",
        "\n",
        "    # Get dataset\n",
        "    train_batches, validation_batches, test_batches = preprocessed_dataset()\n",
        "\n",
        "    # Initialise ResNet\n",
        "    resnet = init_model()\n",
        "\n",
        "    # Train ResNet model\n",
        "    trained_resnet = train_model(resnet, train_batches, validation_batches)\n",
        "\n",
        "    # Evaluate ResNet model\n",
        "    evaluate_model(trained_resnet, test_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-30 22:18:20.384301: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2024-03-30 22:18:20.384327: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-03-30 22:18:20.384333: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-03-30 22:18:20.384366: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-03-30 22:18:20.384384: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "/Users/danielhuang/venv-metal/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"ResNet20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 16)           64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 16)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 16)           2320      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 16)           64        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 16)           64        ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 16)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    , 'activation[0][0]']         \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 16)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 16)           64        ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 16)           64        ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 16)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    , 'activation_2[0][0]']       \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 32, 32, 16)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 16)           64        ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 16)           64        ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 32, 32, 16)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'activation_4[0][0]']       \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 16)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 32)           4640      ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 32)           128       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)           9248      ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 16, 16, 32)           0         ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 32)           128       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 32)           128       ['lambda[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    , 'batch_normalization_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 16, 16, 32)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 32)           9248      ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 32)           128       ['conv2d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 32)           128       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 32)           0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 32)           128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 32)           128       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 16, 16, 32)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 16, 16, 32)           0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 64)             18496     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 8, 8, 64)             256       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 8, 8, 64)             0         ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 64)             256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 8, 8, 64)             256       ['lambda_1[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 8, 8, 64)             0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 8, 8, 64)             256       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 64)             256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_18[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 8, 8, 64)             0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 8, 8, 64)             256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 8, 8, 64)             256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 8, 8, 64)             0         ['batch_normalization_20[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 8, 8, 64)             0         ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['activation_18[0][0]']       \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   650       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 272170 (1.04 MB)\n",
            "Trainable params: 270602 (1.03 MB)\n",
            "Non-trainable params: 1568 (6.12 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'batch_s' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtraining_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mtraining_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m resnet \u001b[38;5;241m=\u001b[39m init_model()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train ResNet model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m trained_resnet \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate ResNet model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m evaluate_model(trained_resnet, test_batches)\n",
            "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_batches, validation_batches)\u001b[0m\n\u001b[1;32m      7\u001b[0m config \u001b[38;5;241m=\u001b[39m model_configuration()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fit data to model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_steps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/venv-metal/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mcrop_generator\u001b[0;34m(batches, crop_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m batch_x, batch_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(batches)\n\u001b[1;32m     20\u001b[0m batch_crops \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], crop_length, crop_length, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mbatch_s\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     22\u001b[0m     batch_crops[i] \u001b[38;5;241m=\u001b[39m random_crop(batch_x[i], (crop_length, crop_length))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (batch_crops, batch_y)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_s' is not defined"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\": \n",
        "    training_process()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv-metal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
